# Proyecto: VisualizaciÃ³n y PredicciÃ³n con Red Convolucional entrenada en MNIST

Este proyecto consiste en trabajar con un modelo convolucional previamente entrenado en el conjunto de datos MNIST. El objetivo es explorar y visualizar sus **kernels**, **mapas de activaciÃ³n** y probarlo con **imÃ¡genes propias** procesadas para hacer predicciones.

---

## ğŸ§  Punto 1: Â¿CÃ³mo son los kernels del modelo preentrenado?

**Â¿QuÃ© se hace?**

Se cargan los pesos del modelo (`mnist_model.h5`) y se extraen los **kernels** (filtros) de la **primera capa convolucional**. Estos filtros son los que el modelo ha aprendido para detectar patrones simples como bordes, lÃ­neas, etc.

**Â¿QuÃ© se muestra?**

- Se visualizan los primeros 10 kernels aplicados al primer canal de entrada.
- Se imprimen los valores numÃ©ricos de esos kernels para analizar su contenido.

**Â¿Para quÃ© sirve?**

Para entender cÃ³mo el modelo "ve" y procesa las imÃ¡genes: estos filtros son fundamentales para extraer caracterÃ­sticas Ãºtiles para la clasificaciÃ³n.

---

## ğŸŒ€ Punto 2: Â¿CÃ³mo se ve la salida de la convoluciÃ³n con los kernels?

**Â¿QuÃ© se hace?**

Se toma una imagen del conjunto de prueba de MNIST (por ejemplo `x_test[1]`) y se pasa a travÃ©s del modelo **hasta la primera capa convolucional**.

**Â¿QuÃ© se muestra?**

Se visualizan los **feature maps** generados por la convoluciÃ³n de la imagen con los primeros 10 kernels. Cada mapa representa cÃ³mo responde un filtro especÃ­fico ante la imagen.

**Â¿Para quÃ© sirve?**

Permite visualizar cÃ³mo cada filtro "detecta" diferentes partes de una imagen: bordes, zonas oscuras, lÃ­neas, etc. Es la primera etapa del "proceso visual" del modelo.

---

## ğŸ–¼ï¸ Punto 3: Â¿CÃ³mo se predicen dÃ­gitos en imÃ¡genes propias?

**Â¿QuÃ© se hace?**

Se procesan 10 imÃ¡genes propias (una por cada dÃ­gito del 0 al 9). Para que sean compatibles con el modelo, se aplican los siguientes pasos de **preprocesamiento**:

1. Convertir a escala de grises.
2. Redimensionar a 28x28 pÃ­xeles.
3. Invertir blanco y negro (fondo negro, nÃºmero blanco).
4. Centrar el nÃºmero en la imagen.
5. Normalizar a valores entre 0 y 1.
6. Dar forma `(28, 28, 1)`.

**Â¿QuÃ© se muestra?**

- Se visualizan las imÃ¡genes procesadas.
- Se muestran las predicciones del modelo sobre cada una.

**Â¿Para quÃ© sirve?**

Demuestra que el modelo puede generalizar mÃ¡s allÃ¡ del dataset original si las imÃ¡genes externas son correctamente preprocesadas.

---

## ğŸ”„ Punto 4: Â¿QuÃ© ocurre si aplico los kernels a una imagen propia?

**Â¿QuÃ© se hace?**

Se selecciona una de las imÃ¡genes propias (por ejemplo `5.jpg`), se preprocesa y se pasa **a travÃ©s de la primera capa convolucional** del modelo.

**Â¿QuÃ© se muestra?**

Se visualizan los **feature maps** resultantes (salidas de la convoluciÃ³n) de esta imagen con los 10 primeros filtros del modelo.

**Â¿Para quÃ© sirve?**

Permite comparar visualmente cÃ³mo el modelo procesa una imagen real frente a una imagen del dataset original. Es Ãºtil para evaluar si el preprocesamiento fue exitoso.

---

## ğŸ“¦ Requisitos del entorno

- TensorFlow
- OpenCV (`cv2`)
- NumPy
- Matplotlib
- PIL (opcional, para carga de imÃ¡genes propias)

---

## GRUPOS DE TRABAJO
- mIGUEL diaz 
- Cesar Porras
- Over Medrano

